\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{GW150914,GW170817,GWTC1,GWTC2,GWTC3,GWTC3_pop_analysis,GWTC2_GR,siren}
\citation{Thrane_2019}
\citation{LIGO_guide_signalextraction}
\citation{bilby_paper}
\citation{dynesty}
\citation{aLIGO,aVirgo,aLVK_prospects}
\citation{ET_science_case}
\citation{HuAccelerationReview}
\citation{wong2023fastgravitationalwaveparameter}
\citation{flowMC}
\citation{ripple}
\citation{yallup2025nested}
\citation{cabezas2024blackjax}
\newlabel{firstpage}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{skilling,Thrane_2019,lal,bilby_paper,LIGO_guide_signalextraction}
\citation{Bayes1763}
\citation{LIGO_guide_signalextraction}
\citation{skilling}
\citation{NSNature}
\citation{yallup2025nested,cabezas2024blackjax}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Bayesian inference in GW astronomy}{2}{subsection.2.1}\protected@file@percent }
\newlabel{sec:background_bayes}{{2.1}{2}{}{subsection.2.1}{}}
\newlabel{eq:bayes_theorem}{{1}{2}{}{equation.1}{}}
\newlabel{eq:evidence}{{2}{2}{}{equation.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}GPU-accelerated nested sampling}{2}{subsection.2.2}\protected@file@percent }
\newlabel{sec:background_ns_and_gpus}{{2.2}{2}{}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}The nested sampling algorithm}{2}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{sec:background_ns}{{2.2.1}{2}{}{subsubsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}GPU architectures for scientific computing}{2}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{sec:background_gpus}{{2.2.2}{2}{}{subsubsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}A vectorized formulation of nested sampling}{2}{subsubsection.2.2.3}\protected@file@percent }
\newlabel{sec:background_vectorized_ns}{{2.2.3}{2}{}{subsubsection.2.2.3}{}}
\citation{bilby_paper,dynesty}
\citation{DE,DE2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Recovered posteriors for the 4s signal. The posteriors are in agreement with each other, demonstrating that \texttt  {blackjax ns} implementation with our custom kernel is functionally equivalent to the \texttt  {bilby} + \texttt  {dynesty} implementation.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:4s_posteriors}{{1}{3}{Recovered posteriors for the 4s signal. The posteriors are in agreement with each other, demonstrating that \texttt {blackjax ns} implementation with our custom kernel is functionally equivalent to the \texttt {bilby} + \texttt {dynesty} implementation}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The inner sampling kernel}{3}{subsection.3.1}\protected@file@percent }
\newlabel{sec:methods_kernel}{{3.1}{3}{}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of the number of live points in the sequential CPU and batched GPU implementations. Although the nominal number of live points used in \texttt  {blackjax ns} is higher than in \texttt  {bilby}, the saw-tooth pattern means that the effective number of live points is the same.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:nlive_comparison}{{2}{3}{Comparison of the number of live points in the sequential CPU and batched GPU implementations. Although the nominal number of live points used in \texttt {blackjax ns} is higher than in \texttt {bilby}, the saw-tooth pattern means that the effective number of live points is the same}{figure.2}{}}
\citation{skilling}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sampler configuration and settings}{4}{subsection.3.2}\protected@file@percent }
\newlabel{sec:sampler_config}{{3.2}{4}{}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of the sample weights for each dead point for the sequential CPU and batched GPU implementations. The weights are calculated using the prior volumes enclosed between successive dead points. The shapes are similar, and both implementations enter the bulk of the posterior distribution at similar iterations, indiciating that setting the number of live points in \texttt  {blackjax ns} to 1.4 times the number of live points in \texttt  {bilby} does indeed result in a like-for-like comparison. The same saw-tooth pattern can be seen in the weights for the \texttt  {blackjax ns} implementation.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:weights_comparison}{{3}{4}{Comparison of the sample weights for each dead point for the sequential CPU and batched GPU implementations. The weights are calculated using the prior volumes enclosed between successive dead points. The shapes are similar, and both implementations enter the bulk of the posterior distribution at similar iterations, indiciating that setting the number of live points in \texttt {blackjax ns} to 1.4 times the number of live points in \texttt {bilby} does indeed result in a like-for-like comparison. The same saw-tooth pattern can be seen in the weights for the \texttt {blackjax ns} implementation}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Setting $n_{\text  {GPU}}$}{4}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{sec:setting_n_gpu}{{3.2.1}{4}{}{subsubsection.3.2.1}{}}
\citation{ripple}
\citation{TL_relativebinning,relativebinning2,relativebinning3,relativebinning4}
\citation{Khan:2015jqa}
\citation{bilby_validation}
\newlabel{eq:gpu_compression}{{5}{5}{}{equation.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Likelihood}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Priors}{5}{subsection.3.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Prior distributions for the parameters of the binary black hole system. The specific ranges for the masses and spins are dependent on the injection and are specified in Section~\ref {sec:results}.}}{5}{table.1}\protected@file@percent }
\newlabel{tab:priors}{{1}{5}{Prior distributions for the parameters of the binary black hole system. The specific ranges for the masses and spins are dependent on the injection and are specified in Section~\ref {sec:results}}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and discussion}{5}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{5}{}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Simulated signals}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}4-second simulated signal}{5}{subsubsection.4.1.1}\protected@file@percent }
\newlabel{sec:4s_simulated_signal}{{4.1.1}{5}{}{subsubsection.4.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Injection parameters for the 4s signal.}}{6}{table.2}\protected@file@percent }
\newlabel{tab:injection_params}{{2}{6}{Injection parameters for the 4s signal}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of the log evidence for the 4s signal. The results are in excellent agreement, demonstrating the robustness of the \texttt  {blackjax ns} implementation in recovering the same posteriors and evidence as the \texttt  {bilby} implementation. This unifies parameter estimation and evidence evaluation into a single GPU-accelerated framework.}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:4s_logZ_comparison}{{4}{6}{Comparison of the log evidence for the 4s signal. The results are in excellent agreement, demonstrating the robustness of the \texttt {blackjax ns} implementation in recovering the same posteriors and evidence as the \texttt {bilby} implementation. This unifies parameter estimation and evidence evaluation into a single GPU-accelerated framework}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of the wall-times and cost savings for the 4s signal.}}{6}{table.3}\protected@file@percent }
\newlabel{tab:4s_time_comparison}{{3}{6}{Comparison of the wall-times and cost savings for the 4s signal}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of the network signal-to-noise ratios (SNR) for the injected signals.}}{6}{figure.5}\protected@file@percent }
\newlabel{fig:snr_dist}{{5}{6}{Distribution of the network signal-to-noise ratios (SNR) for the injected signals}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Injection Study}{6}{subsection.4.2}\protected@file@percent }
\newlabel{sec:injection_study}{{4.2}{6}{}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison of the chain lengths for the sequential CPU and batched GPU implementations. The \texttt  {blackjax ns} implementation can only perform batch tuning, a fundamental algorithmic difference between the CPU-based and GPU-based implementations of the `acceptance-walk' kernel. This leads to a staircase pattern in the chain lengths, which can be seen in the plot. However, setting \texttt  {naccept} = 120 in \texttt  {blackjax ns} and \texttt  {naccept} = 60 in \texttt  {bilby} results in similar average chain lengths for the injection study.}}{7}{figure.6}\protected@file@percent }
\newlabel{fig:chain_length_comparison}{{6}{7}{Comparison of the chain lengths for the sequential CPU and batched GPU implementations. The \texttt {blackjax ns} implementation can only perform batch tuning, a fundamental algorithmic difference between the CPU-based and GPU-based implementations of the `acceptance-walk' kernel. This leads to a staircase pattern in the chain lengths, which can be seen in the plot. However, setting \texttt {naccept} = 120 in \texttt {blackjax ns} and \texttt {naccept} = 60 in \texttt {bilby} results in similar average chain lengths for the injection study}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Percentile-percentile (PP) coverage plot for the 100-injection study, obtained with the \texttt  {blackjax ns} sampler. The cumulative fraction of events where the true injected parameter falls below a given credible level is plotted against that credible level. The proximity of all parameter curves to the diagonal indicates that the posterior credible intervals are statistically well-calibrated. A corresponding plot for the \texttt  {bilby+dynesty} analysis, which should be identical, is provided in the Appendix for reference.}}{7}{figure.7}\protected@file@percent }
\newlabel{fig:pp_coverage}{{7}{7}{Percentile-percentile (PP) coverage plot for the 100-injection study, obtained with the \texttt {blackjax ns} sampler. The cumulative fraction of events where the true injected parameter falls below a given credible level is plotted against that credible level. The proximity of all parameter curves to the diagonal indicates that the posterior credible intervals are statistically well-calibrated. A corresponding plot for the \texttt {bilby+dynesty} analysis, which should be identical, is provided in the Appendix for reference}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The wall-time speedups for all 100 events in the injection study.}}{7}{figure.8}\protected@file@percent }
\newlabel{fig:speedup_comparison}{{8}{7}{The wall-time speedups for all 100 events in the injection study}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The cost reductions for all 100 events in the injection study.}}{7}{figure.9}\protected@file@percent }
\newlabel{fig:cost_reduction}{{9}{7}{The cost reductions for all 100 events in the injection study}{figure.9}{}}
\citation{yallup2025nested}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Disentangling Sources of GPU Acceleration}{8}{subsection.4.3}\protected@file@percent }
\newlabel{sec:disentangling_acceleration}{{4.3}{8}{}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}8-second simulated signal}{8}{subsection.4.4}\protected@file@percent }
\newlabel{sec:8s_simulated_signal}{{4.4}{8}{}{subsection.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Injection parameters for the 8s signal.}}{8}{table.4}\protected@file@percent }
\newlabel{tab:8s_injection_params}{{4}{8}{Injection parameters for the 8s signal}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{8}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Recovered posterior distributions for the 8s simulated signal, comparing our GPU-based \texttt  {blackjax ns} sampler with the CPU-based \texttt  {bilby} sampler. The injected values are marked by black lines. The strong statistical agreement confirms the validity of our implementation for longer-duration signals. Despite requiring more likelihood evaluations for this analysis, the GPU implementation still provided a wall-time speedup of 26.2$\times $ and a cost reduction of 1.64$\times $.}}{9}{figure.10}\protected@file@percent }
\newlabel{fig:8s_posteriors}{{10}{9}{Recovered posterior distributions for the 8s simulated signal, comparing our GPU-based \texttt {blackjax ns} sampler with the CPU-based \texttt {bilby} sampler. The injected values are marked by black lines. The strong statistical agreement confirms the validity of our implementation for longer-duration signals. Despite requiring more likelihood evaluations for this analysis, the GPU implementation still provided a wall-time speedup of 26.2$\times $ and a cost reduction of 1.64$\times $}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Comparison of the recovered log-evidence ($Z$) for the 8s signal. The results from both the \texttt  {bilby} and \texttt  {blackjax ns} frameworks are consistent within their estimated numerical uncertainties.}}{9}{figure.11}\protected@file@percent }
\newlabel{fig:8s_logZ}{{11}{9}{Comparison of the recovered log-evidence ($Z$) for the 8s signal. The results from both the \texttt {bilby} and \texttt {blackjax ns} frameworks are consistent within their estimated numerical uncertainties}{figure.11}{}}
\citation{yallup2025nested}
\citation{Williams2021Nessai}
\citation{Prathaban}
\bibstyle{mnras}
\bibdata{references}
\bibcite{GW150914}{{1}{2016}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GW170817}{{2}{2017a}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{siren}{{3}{2017b}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GWTC1}{{4}{2019}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{aLVK_prospects}{{5}{2020a}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{LIGO_guide_signalextraction}{{6}{2020b}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GWTC2_GR}{{7}{2021}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GWTC3_pop_analysis}{{8}{2023a}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GWTC3}{{9}{2023b}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{GWTC2}{{10}{2024}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{aVirgo}{{11}{2014}{{Acernese et~al.}}{{Acernese et~al.,}}}
\bibcite{bilby_paper}{{12}{2019}{{Ashton et~al.}}{{Ashton et~al.}}}
\bibcite{NSNature}{{13}{2022}{{Ashton et~al.}}{{Ashton, Bernstein, Buchner \& et al.}}}
\bibcite{Bayes1763}{{14}{1763}{{{Bayes}}}{{{Bayes}}}}
\bibcite{ET_science_case}{{15}{2023}{{Branchesi et~al.}}{{Branchesi et~al.}}}
\bibcite{cabezas2024blackjax}{{16}{2024}{{Cabezas et~al.}}{{Cabezas, Corenflos, Lao \& Louf}}}
\bibcite{relativebinning4}{{17}{2013}{{Cornish}}{{Cornish}}}
\bibcite{ripple}{{18}{2024}{{Edwards et~al.}}{{Edwards, Wong, Lam, Coogan, Foreman-Mackey, Isi \& Zimmerman}}}
\bibcite{Higson_Errors}{{19}{2018}{{Higson et~al.}}{{Higson, Handley, Hobson \& Lasenby}}}
\bibcite{HuAccelerationReview}{{20}{2024}{{Hu \& Veitch}}{{Hu \& Veitch}}}
\bibcite{Khan:2015jqa}{{21}{2016}{{Khan et~al.}}{{Khan, Husa, Hannam, Ohme, P\"urrer, Jim\'enez~Forteza \& Boh\'e}}}
\bibcite{TL_relativebinning}{{22}{2023}{{Krishna et~al.}}{{Krishna, Vijaykumar, Ganguly, Talbot, Biscoveanu, George, Williams \& Zimmerman}}}
\bibcite{relativebinning3}{{23}{2021}{{Leslie et~al.}}{{Leslie, Dai \& Pratten}}}
\bibcite{Prathaban_PE_errors}{{24}{2024}{{Prathaban \& Handley}}{{Prathaban \& Handley}}}
\bibcite{Prathaban}{{25}{2025}{{Prathaban et~al.}}{{Prathaban, Bevins \& Handley}}}
\bibcite{bilby_validation}{{26}{2020}{{Romero-Shaw et~al.}}{{Romero-Shaw et~al.,}}}
\bibcite{skilling}{{27}{2006}{{Skilling}}{{Skilling}}}
\bibcite{dynesty}{{28}{2020}{{Speagle}}{{Speagle}}}
\bibcite{DE}{{29}{1997}{{Storn \& Price}}{{Storn \& Price}}}
\bibcite{aLIGO}{{30}{2015}{{{The LIGO Scientific Collaboration} et~al.}}{{{The LIGO Scientific Collaboration} et~al.}}}
\bibcite{Thrane_2019}{{31}{2019}{{Thrane \& Talbot}}{{Thrane \& Talbot}}}
\bibcite{lal}{{32}{2015}{{Veitch et~al.}}{{Veitch et~al.,}}}
\bibcite{Williams2021Nessai}{{33}{2021}{{{Williams} et~al.}}{{{Williams}, {Veitch} \& {Messenger}}}}
\bibcite{wong2023fastgravitationalwaveparameter}{{34}{2023a}{{Wong et~al.}}{{Wong, Isi \& Edwards}}}
\bibcite{flowMC}{{35}{2023b}{{Wong et~al.}}{{Wong, Gabri\'e \& Foreman-Mackey}}}
\bibcite{yallup2025nested}{{36}{2025}{{Yallup et~al.}}{{Yallup, Kroupa \& Handley}}}
\bibcite{relativebinning2}{{37}{2018}{{Zackay et~al.}}{{Zackay, Dai \& Venumadhav}}}
\bibcite{DE2}{{38}{2006}{{{ter Braak}}}{{{ter Braak}}}}
\citation{skilling,Higson_Errors}
\citation{Prathaban_PE_errors}
\@writefile{toc}{\contentsline {section}{\numberline {A}PP coverage plot for \texttt  {bilby + dynesty}}{11}{section.A1}\protected@file@percent }
\newlabel{app:bilby_pp_plot}{{A}{11}{}{section.A1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Full run statistics for injection study}{11}{section.A2}\protected@file@percent }
\newlabel{app:injection_study_stats}{{B}{11}{}{section.A2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A1}{\ignorespaces PP coverage plot for the 100-injection study, obtained with the CPU-based \texttt  {bilby+dynesty} sampler. This plot is provided for direct comparison with the results from our \texttt  {blackjax ns} implementation shown in Figure~\ref {fig:pp_coverage}. The results confirm that the CPU-based and GPU-based implementations are functionally similar.}}{11}{figure.A1.1}\protected@file@percent }
\newlabel{fig:pp_coverage_bilby}{{A1}{11}{PP coverage plot for the 100-injection study, obtained with the CPU-based \texttt {bilby+dynesty} sampler. This plot is provided for direct comparison with the results from our \texttt {blackjax ns} implementation shown in Figure~\ref {fig:pp_coverage}. The results confirm that the CPU-based and GPU-based implementations are functionally similar}{figure.A1.1}{}}
\newlabel{lastpage}{{B}{11}{}{figure.A2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B1}{\ignorespaces Comparison of internal run statistics for the 100-injection study. From left to right: the mean number of MCMC steps (walk length) per iteration, the mean number of accepted steps, and the mean acceptance rate, for both the \texttt  {bilby} and \texttt  {blackjax ns} runs. The batch-adaptive nature of the GPU sampler can lead to outlier runs with longer chains and lower acceptance rates, as discussed in Appendix~\ref {app:injection_study_stats}.}}{12}{figure.A2.1}\protected@file@percent }
\newlabel{fig:injection_study_stats}{{B1}{12}{Comparison of internal run statistics for the 100-injection study. From left to right: the mean number of MCMC steps (walk length) per iteration, the mean number of accepted steps, and the mean acceptance rate, for both the \texttt {bilby} and \texttt {blackjax ns} runs. The batch-adaptive nature of the GPU sampler can lead to outlier runs with longer chains and lower acceptance rates, as discussed in Appendix~\ref {app:injection_study_stats}}{figure.A2.1}{}}
\gdef \@abspage@last{12}
